{
  "name": "gulp-awspublish",
  "version": "1.0.1",
  "description": "gulp plugin to publish files to amazon s3",
  "keywords": [
    "gulpplugin",
    "aws",
    "s3",
    "publish"
  ],
  "homepage": "https://github.com/pgherveou/gulp-awspublish",
  "bugs": {
    "url": "https://github.com/pgherveou/gulp-awspublish/issues"
  },
  "author": {
    "name": "PG Herveou",
    "email": "pg@jogabo.com",
    "url": "https://github.com/pgherveou"
  },
  "main": "./lib/index.js",
  "repository": {
    "type": "git",
    "url": "git://github.com/pgherveou/gulp-awspublish.git"
  },
  "scripts": {
    "test": "istanbul test _mocha --report html -- test/*.js --reporter spec",
    "coveralls": "istanbul cover ./node_modules/mocha/bin/_mocha --report lcovonly -- -R spec && cat ./coverage/lcov.info | ./node_modules/coveralls/bin/coveralls.js && rm -rf ./coverage"
  },
  "dependencies": {
    "aws-sdk": "^2.1.7",
    "clone": "0.x",
    "gulp-util": "2.x",
    "mime": "1.x",
    "pad-component": "0.x",
    "pascal-case": "^1.1.0",
    "through2": "0.x",
    "xml-json": "^2.0.2"
  },
  "devDependencies": {
    "chai": "*",
    "concurrent-transform": "^1.0.0",
    "coveralls": "*",
    "event-stream": "^3.2.1",
    "gulp-rename": "*",
    "istanbul": "*",
    "mocha": "*",
    "mocha-lcov-reporter": "*"
  },
  "engines": {
    "node": ">=0.8.0",
    "npm": ">=1.2.10"
  },
  "licenses": [
    {
      "type": "MIT"
    }
  ],
  "readme": "# gulp-awspublish\n[![NPM version][npm-image]][npm-url] [![Dependency Status][depstat-image]][depstat-url]\n\n> awspublish plugin for [gulp](https://github.com/wearefractal/gulp)\n\n## Usage\n\nFirst, install `gulp-awspublish` as a development dependency:\n\n```shell\nnpm install --save-dev gulp-awspublish\n```\n\nThen, add it to your `gulpfile.js`:\n\n```javascript\nvar awspublish = require('gulp-awspublish');\n\ngulp.task('publish', function() {\n\n  // create a new publisher\n  var publisher = awspublish.create({ bucket: '...' });\n\n  // define custom headers\n  var headers = {\n     'Cache-Control': 'max-age=315360000, no-transform, public'\n     // ...\n   };\n\n  return gulp.src('./public/*.js')\n\n     // gzip, Set Content-Encoding headers and add .gz extension\n    .pipe(awspublish.gzip({ ext: '.gz' }))\n\n    // publisher will add Content-Length, Content-Type and headers specified above\n    // If not specified it will set x-amz-acl to public-read by default\n    .pipe(publisher.publish(headers))\n\n    // create a cache file to speed up consecutive uploads\n    .pipe(publisher.cache())\n\n     // print upload updates to console\n    .pipe(awspublish.reporter());\n});\n\n// output\n// [gulp] [create] file1.js.gz\n// [gulp] [create] file2.js.gz\n// [gulp] [update] file3.js.gz\n// [gulp] [cache]  file3.js.gz\n// ...\n```\n\n* Note: If you follow the [aws-sdk suggestions](http://docs.aws.amazon.com/AWSJavaScriptSDK/guide/node-configuring.html) for\n  providing your credentials you don't need to pass them in to create the publisher.\n\n## Testing\n\nadd an aws-credentials.json json file to the project directory\nwith your bucket credentials, then run mocha.\n\n```json\n {\n  \"key\": \"...\",\n  \"secret\": \"...\",\n  \"bucket\": \"...\"\n}\n```\n\n## API\n\n### awspublish.gzip(options)\n\ncreate a through stream, that gzip file and add Content-Encoding header.\n\nAvailable options:\n  - ext: file extension to add to gzipped file (eg: { ext: '.gz' })\n\n### awspublish.create(options)\n\nCreate a Publisher.\nOptions are used to create an `aws-sdk` S3 client. At a minimum you must pass\na `bucket` option, to define the site bucket. If you are using the [aws-sdk suggestions](http://docs.aws.amazon.com/AWSJavaScriptSDK/guide/node-configuring.html) for credentials you do not need\nto provide anything else.\n\nAlso supports credentials specified in the old [knox](https://github.com/LearnBoost/knox#client-creation-options)\nformat, a `profile` property for choosing a specific set of shared AWS creds, or and `accessKeyId` and `secretAccessKey` provided explicitly.\n\n#### Publisher.publish([headers], [options])\n\nCreate a through stream, that push files to s3.\n- header: hash of headers to add or override to existing s3 headers.\n- options: optional additional publishing options\n  - force: bypass cache / skip\n  - simulate: debugging option to simulate s3 upload\n  - createOnly: skip file updates\n\nFiles that go through the stream receive extra properties:\n\n  - s3.path: s3 path\n  - s3.etag: file etag\n  - s3.date: file last modified date\n  - s3.state: publication state (create, update, delete, cache or skip)\n  - s3.headers: s3 headers for this file. Defaults headers are:\n    - x-amz-acl: public-read\n    - Content-Type\n    - Content-Length\n\n#### publisher.cache()\n\nCreate a through stream that create or update a cache file using file s3 path and file etag.\nConsecutive runs of publish will use this file to avoid reuploading identical files.\n\nCache file is save in the current working dir and is named `.awspublish-<bucket>`. The cache file is flushed to disk every 10 files just to be safe.\n\n#### Publisher.sync([prefix])\n\ncreate a transform stream that delete old files from the bucket.\nYou can speficy a prefix to sync a specific directory.\n\n> **warning** `sync` will delete files in your bucket that are not in your local folder.\n\n```js\n// this will publish and sync bucket files with the one in your public directory\ngulp.src('./public/*')\n  .pipe(publisher.publish())\n  .pipe(publisher.sync())\n  .pipe(awspublish.reporter());\n\n// output\n// [gulp] [create] file1.js\n// [gulp] [update] file2.js\n// [gulp] [delete] file3.js\n// ...\n\n```\n\n#### Publisher.client\n\nThe `aws-sdk` S3 client is exposed to let you do other s3 operations.\n\n### awspublish.reporter([options])\n\nCreate a reporter that logs s3.path and s3.state (delete, create, update, cache, skip).\n\nAvailable options:\n  - states: list of state to log (default to all)\n\n```js\n// this will publish,sync bucket files and print created, updated and deleted files\ngulp.src('./public/*')\n  .pipe(publisher.publish())\n  .pipe(publisher.sync())\n  .pipe(awspublish.reporter({\n      states: ['create', 'update', 'delete']\n    }));\n```\n\n## Examples\n\n### rename file & directory\n\nYou can use `gulp-rename` to rename your files on s3\n\n```js\n// see examples/rename.js\n\ngulp.src('examples/fixtures/*.js')\n    .pipe(rename(function (path) {\n        path.dirname += '/s3-examples';\n        path.basename += '-s3';\n    }))\n    .pipe(publisher.publish())\n    .pipe(awspublish.reporter());\n\n// output\n// [gulp] [create] s3-examples/bar-s3.js\n// [gulp] [create] s3-examples/foo-s3.js\n```\n\n### upload file in parallel\n\nYou can use `concurrent-transform` to upload files in parallel to your amazon bucket\n\n```js\nvar parallelize = require(\"concurrent-transform\");\n\ngulp\n  .src('examples/fixtures/*.js')\n  .pipe(parallelize(publisher.publish(), 10))\n  .pipe(awspublish.reporter());\n```\n\n## Plugins\n\n### gulp-awspublish-router\nA router for defining file-specific rules\nhttps://www.npmjs.org/package/gulp-awspublish-router\n\n## License\n\n[MIT License](http://en.wikipedia.org/wiki/MIT_License)\n\n[npm-url]: https://npmjs.org/package/gulp-awspublish\n[npm-image]: https://badge.fury.io/js/gulp-awspublish.png\n\n[depstat-url]: https://david-dm.org/pgherveou/gulp-awspublish\n[depstat-image]: https://david-dm.org/pgherveou/gulp-awspublish.png\n",
  "readmeFilename": "README.md",
  "_id": "gulp-awspublish@1.0.1",
  "dist": {
    "shasum": "158d840126ec5569f63b65f6f995d4b757be23bb"
  },
  "_from": "gulp-awspublish@",
  "_resolved": "https://registry.npmjs.org/gulp-awspublish/-/gulp-awspublish-1.0.1.tgz"
}
